\chapter{Divisão e conquista}
\label{DivConq}

%----------------------------------------------------------------------------------------

Neste capítulo será apresentada uma técnica que chamamos de otimização por divisão e conquista. A ideia é citada por Aggarwal~\cite{Aggarwal:1987} e é um tópico recorrente em competições de programação, sendo conhecida como ``Divide and Conquer Optimization''~\cite{Quora:DivConq,CF:Optm} e geralmente aplicada a problemas de programação dinâmica. 

Além disso, as hipóteses dos algoritmos decorrentes desta técnica são mais fracas do que as do algoritmo SMAWK, apresentado no Capítulo~\ref{SMAWK}, portanto, todo problema para o qual o SMAWK pode ser aplicado, também pode ser resolvido com esta técnica. Ao final deste capítulo, apresentamos exemplos de aplicações em programação dinâmica e discutimos a interpretação desta técnica sob o olhar da programação competitiva.

Dada uma matriz $A \in \B{Q}^{n \times m}$, listamos os casos de uso desta técnica:
\begin{itemize}
    \item Se $A$ é monótona nos mínimos das linhas podemos encontrar os índices de mínimos das linhas em tempo $\Cl{O}((n+m)\lg(n))$, 
    \item se $A$ é monótona nos máximos das linhas podemos encontrar os índices de máximos das linhas em tempo $\Cl{O}((n+m)\lg(n))$, 
    \item se $A$ é monótona nos mínimos das colunas podemos encontrar os índices de mínimos das colunas em tempo $\Cl{O}((n+m)\lg(m))$ e 
    \item se $A$ é monótona nos máximos das colunas podemos encontrar os índices de máximos das colunas em tempo $\Cl{O}((n+m)\lg(m))$.
\end{itemize}

Apresentaremos o caso em que $A$ é crescente nos mínimos das linhas. É fácil manipular o algoritmo resultante para trabalhar com os outros casos.

%----------------------------------------------------------------------------------------

\section{Técnica}
Dada uma matriz $A \in \B{Q}^{n \times m}$ monótona crescente nos mínimos das linhas, queremos encontrar o vetor de índices de mínimos das linhas de $A$. Isto é, para todo $i \in [n]$, queremos encontrar
$$ R[i] = \min\{j \mid A[i][j] \leq A[i][j'] \text{ para todo } j' \in [m]\} \text{.}$$  

Se, para alguma linha~$i$, encontrarmos o valor~$R[i]$, sabemos, pela monotonicidade de~$A$, que~${ R[i'] \leq R[i] }$ para todo~${ i' < i }$ e que~${ R[i'] \geq R[i] }$ para todo~${ i' > i }$, isto é, sabemos que os mínimos das outras linhas se encontram nas submatrizes~${ A[1 \tdots i-1][1 \tdots R[i]] }$ e~${ A[i+1 \tdots n][R[i] \tdots m] }$. Seguindo o paradigma de divisão e conquista, vamos resolver o mesmo problema para estas submatrizes e, consequentemente, resolver o problema original. O Algoritmo~\ref{ DivConq:algo } implementa esta ideia.

\newcommand{\DivConq}{\textsc{DivConq}}
\begin{algorithm}[h]
\caption{Mínimos das linhas com divisão e conquista}
\label{ DivConq:algo }
\begin{algorithmic}[1]
\Function{\DivConq}{A, r_s, r_t, c_s, c_t, R}
    \If{ $r_s \leq r_t$ }
        \State $\ell \rec \ceil{ (r_s + r_t)/2 }$
        \State Guarda em $R[\ell]$ o índice de mínimo da linha~$\ell$ de~$A$. \label{ DivConq:algo:findmin }
        \State $\DivConq(A,r_s,\ell-1,c_s,R[\ell],R)$
        \State $\DivConq(A,\ell+1,r_t,R[\ell],c_t,R)$
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

Note que, na linha~\ref{ DivConq:algo:findmin }, o mínimo só precisa ser buscado entre os índices~$c_s$ e~$c_t$, inclusive, pois estamos resolvendo o problema para a submatriz~$A[r_s \tdots r_t][c_s \tdots c_t]$. A implementação desta função em~\texttt{C++} pode ser encontrada no arquivo~\texttt{DivConq.cpp}.

\begin{figure}[h]
    \centering
    \input{Figures/DivConq.tikz}
    \caption{Progressão do algoritmo da divisão e conquista em uma matriz monótona. A cada chamada da função, as células circuladas em verde são percorridas linearmente. Os mínimos encontrados estão hachuradas em vermelho.} \label{ DivConq:Figure }
\end{figure}

Vamos realizar uma análise do tempo gasto pelo Algoritmo~\ref{ DivConq:algo } no pior caso. Se~$A$ é uma matriz e~${ r_s,r_t,c_s }$ e~$c_t$ são índices tais que~${ r_t - r_s + 1 = n \geq 0 }$ e~${ c_t - c_s + 1 = m > 0 }$, o tempo gasto por~$\DivConq(A,r_s,r_t,c_s,c_t,R)$ no pior caso pode ser expresso pela seguinte recorrência:
\begin{equation*}
\arraycolsep=2pt
T(n,m) = \left\{
\begin{array}{ll}
    1 &  \text{, se } n = 0 \text{ e } \\
    m + \max\limits_{j \in [m]}\{ T(\floor{ \frac{n}{2} },j) + T(\ceil{ \frac{n}{2} } - 1, m - j + 1) \} & \text{, caso contrário.} \\
\end{array}
\right.
\end{equation*}

Vamos provar que~$T(n,m) \leq (m+n)\lg(n + 2)$ para quaisquer dois inteiros~${ n \geq 0 }$ e~$m > 0$ usando indução em~$n$. Se~${ n = 0 }$, então~${ T(n,m) = T(0,m) = 1 \leq m = m\lg(2) =  (m + n)\lg(n+2) }$. Com~${ n > 1 }$ assumimos que a tese vale para todo~${ n' \in [n-1] }$ e, para todo~$m > 0$, sabemos que existe um~${ j \in [m] }$ tal que~${ T(n,m) = T(\floor{ \frac{n}{2} },j) + T(\ceil{ \frac{n}{2} } - 1, m - j + 1) }$. Já que tanto~$\floor{ \frac{n}{2} }$ quanto~$\ceil{ \frac{n}{2} } - 1$ estão em~$[n-1]$, aplicamos a hipótese de indução e obtemos que~${ T(n,m) \leq (\floor{ \frac{n}{2} } + j)\lg(\floor{ \frac{n}{2} } + 2) + (\ceil{ \frac{n}{2} } + m - j)\lg(\ceil{ \frac{n}{2} } + 1) }$. Com esta desigualdade, obtemos que~${ T(n,m) \leq (\floor{ \frac{n}{2} } + j)\lg(n + 2) + (\ceil{ \frac{n}{2} } + m - j)\lg(n + 2) = (n + m)\lg(n+2) }$, o que conclui esta prova.

%----------------------------------------------------------------------------------------

\section{Aplicação em programação dinâmica} \label{DivConq:DP}

Utilizaremos a técnica apresentada aqui para resolver uma adaptação do problema ``Internet Trouble'' da Final Brasileira da Maratona de Programação de 2016. Informações sobre a prova em questão podem ser encontradas no link \url{http://maratona.ime.usp.br/resultados16}.  

\begin{prob} \label{DivConq:InternetTrouble}
Considere a função de custo~$c$ definida como~${ c(v) = \sum\limits_{i=1}^{|v|} \min\{i-1,m-i\} v_i }$ para cada vetor~${ v \in \B{Q}^m }$ com~${ m \in [n] }$. Sejam~${ v \in \B{Z}_+^n }$ um vetor e~$k \in [n]$ um inteiro. Escolher~$k+1$ posições~${ p_0 = 1 \leq p_1 \leq \dots \leq p_k = n }$ do vetor~$v$ de forma a minimizar~${ \sum\limits_{ i = 1 }^k c(v[p_{i-1} \tdots p_i]) }$.
\end{prob}

Podemos dar ao problema acima a interpretação do problema ``Internet Trouble'' citado. Temos~$n$ cidades numeradas de~$1$ até~$n$ dispostas em uma linha de forma que, para todo~$i,j \in [n]$, a distância entre as cidades~$i$ e~$j$ é~$|i-j|$. Queremos escolher~${ k + 1 }$ destas cidades para instalar torres de distribuição de energia de forma a minimizar o custo de alimentar todas as cidades com energia sabendo que o custo de transferir energia de uma torre qualquer para uma cidade com~$h$ habitantes a uma distância~$d$ da torre é~$hd$ e que uma torre pode alimentar quantas cidades quiser. Nesta adaptação, as cidades~$1$ e~$n$ são escolhas obrigatórias para posições de torres. 

Queremos resolver o problema com programação dinâmica. Definimos, para todo~${ \ell \in [k] }$ e~${ j \in [n] }$, o subproblema de escolher~${ \ell + 1 }$ posições~${ p_0 = 1 \leq p_1 \leq \dots \leq p_\ell = j }$ do vetor~$v[1 \tdots j]$ de forma a minimizar~${ \sum\limits_{i = 1}^\ell c(v[p_{i-1} \tdots p_i]) }$. Definimos a matriz~$E$ que guarda em cada entrada~$E[\ell][j]$ a resposta ótima do subproblema de parâmetros~$\ell$ e~$j$. É fácil ver que~$E[k][n]$ guarda a resposta ótima do problema original. O valor de qualquer entrada~$E[1][j]$ do vetor é~$c(v[1 \tdots j])$ já que o único~$p$ possível a ser escolhido é tal que~${ p_0 = 1 }$ e~${ p_1 = j }$. O valor de qualquer entrada~$E[\ell][j]$ do vetor tal que~${ \ell \in [2 \tdots k] }$ é igual a~${ \min\{E[\ell-1][i] + c(v[i \tdots j]) \mid i \in [j] \} }$. Esta definição de~$E$ indica uma solução com programação dinâmica que pode ser realizada em tempo~${ \Cl{O}(kn^2)}$ desde que a função~$c$ possa ser calculada para todo subvetor de~$v$ em tempo~$\Cl{O}(1)$.

Definimos as funções~${ s(i,j) = \sum\limits_{ x = i }^j (x - i)v_x }$ e~${ t(i,j) = \sum\limits_{ x = i }^j (j - x)v_x }$ para todo~${ i,j \in [n] }$ onde~${ i \leq j }$. Assim, é fácil ver que se~${ r = \floor{\frac{i+j}{2}} }$ ou~${ r = \ceil{\frac{i+j}{2}} - 1 }$ vale que~${ c(v[i \tdots j]) = s(i,r) + t(r+1,j) }$. Além disso, se pré calcularmos, em tempo~$\Cl{O}(n)$ os vetores~$a,b \in \B{Z}^{[0 \tdots n]}$ tais que, para todo~${ j \in [n] }$, vale que~${ a_j = \sum\limits_{ i \in [j] } v_i }$ e~${ b_j = \sum\limits_{ i \in [j] } iv_i }$ podemos escrever~${ s(i,j) = b_j - b_{i-1} - (a_j - a_{i-1})i }$ e~${ t(i,j) = (a_j - a_{i-1})j - b_j + b_{i-1} }$ para todo~${ i,j \in [n] }$ o que nos dá uma forma de calcular estas funções em~$\Cl{O}(1)$ e, portanto, calcular~$c$ em~$\Cl{O}(1)$ para todo subvetor de~$v$.

Vamos definir uma matriz~$A \in \B{Z}^{n \times n}$ tal que, para todo~${ \ell \in [2 \tdots k] }$ e~${ j \in [n] }$, valha que~${ E[\ell][j] = \min\{ E[\ell-1][i] + A[i][j] \mid i \in [n] \} }$. Basta escolher~${ A[i][j] = c(v[i \tdots j]) }$ para todo~${ i \leq j }$ e~${ A[i][j] = +\infty }$ para todo~${ i > j }$. Agora, podemos definir uma matriz~$B_\ell$ para cada um destes~$\ell$ de forma que~${ B_\ell[i][j] = E[\ell-1][i] + A[i][j] }$ para todo~${ i,j \in [n] }$. Desta forma, calcular um valor~${ E[\ell][j] }$ com~${ \ell \in [2 \tdots k] }$ é encontrar o mínimo da~$j$-ésima coluna da matriz~${ B_\ell }$. Vamos mostrar que cada uma destas matrizes é monótona nos mínimos das colunas e, com isso, resolver este problema em tempo~$\Cl{O}(kn\lg(n))$ com a otimização da divisão e conquista.

Vamos provar que as matrizes~$B_\ell$ são monótonas crescentes nos mínimos das colunas. Sejam~${ \ell \in [2 \tdots k] }$,~${ j \in [n-1] }$ um índice de coluna de~${ B_\ell }$ e sejam~${ i',i \in [n] }$ duas linhas de~$B_\ell$ tais que~${ i' < i \leq j }$. Suponha que~${ B_\ell[i][j] < B_\ell[i'][j] }$. Temos~${ E[\ell-1][i] + A[i][j] < E[\ell-1][i'] + A[i'][j] }$. Tomamos as médias~${ r = \floor{\frac{i+j}{2}} = \ceil{\frac{i+j+1}{2}} - 1 }$ e~${ r' = \floor{\frac{i'+j+1}{2}} = \ceil{\frac{i'+j+1}{2}} - 1 }$. Vale a desigualdade~${ E[\ell-1][i] + s(i,r) + t(r+1,j) < E[\ell-1][i'] + s(i',r') + t(r'+1,j) }$. Porém, já que~${ r' \leq r }$, vale
\begin{equation*}
\begin{array}{rl}
t(r+1,j+1) - t(r+1,j) & = (j-r)v_{j+1} \\
& \leq (j-r')v_{j+1} \\
& = t(r'+1,j+1) - t(r'+1,j) \text{.}
\end{array}
\end{equation*}
 
Com este resultado concluímos que~${ t(r'+1,j) - t(r+1,j) \leq t(r'+1,j+1) - t(r+1,j+1) }$ e, desta, temos que~${ E[\ell-1][i] + s(i,r) + t(r+1,j+1) < E[\ell-1][i'] + s(i',r') + t(r'+1,j+1) }$, portanto, vale que~${ B_\ell[i][j+1] < B_\ell[i][j+1] }$. Isso nos diz que se algum~${ i \leq j }$ é o índice de mínimo da coluna~$j$, o índice de mínimo da coluna~${j+1}$ não pode ser menor do que~$i$, já que, pelo fato de~${ B_\ell[i][j] = +\infty }$ para todo~${ i > j }$, o índice de mínimo da coluna~$j$ sempre ser menor do que~$j$, este fato nos diz que as matrizes~$B_\ell$ são crescentes nos mínimos das colunas.

%----------------------------------------------------------------------------------------

\section{Interpretação em programação dinâmica} \label{DivConq:Inter_DP}

Muitas das técnicas apresentadas neste trabalho possuem formatos específicos de programas dinâmicos relacionados à técnica. Um bom exemplo é a otimização de Knuth-Yao do Capítulo~\ref{KY}, que é desenvolvida à partir da sua interpretação em programação dinâmica. 

Em contextos voltados para competições de programação, é comum pensar e apresentar estas técnicas com uma visão fortemente voltada para programação dinâmica. Este olhar é bom e especialmente interessante para competições de programação por facilitar a identificação rápida da pertinência de problemas a esta técnica à partir da recorrência. Por este motivo, é interessante discutir esta interpretação também aqui.

\begin{prob} \label{DivConq:DP}
Dados inteiros~$n$ e~$k$ com~$1 \leq k \leq n$ e uma função~$f(i,j)$ definida para todo~${ i,j \in [n] }$ onde~$i \leq j$. Calcular~$E[k][n]$ onde, para todo~${ j \in [0 \tdots n] }$ e~${ \ell \in k }$ vale que
\begin{equation*}
E[\ell][j] = \begin{cases}
A[1][j] & \text{,  se } \ell = 1 \text{ e } \\
\min\{ E[\ell-1][i] + A[i][j] \mid i \in [j] \} & \text{, caso contrário.}
\end{cases}
\end{equation*}
\end{prob}

O Problema~\ref{DivConq:DP} segue um formato clássico de programação dinâmica e indica uma solução clara que custa tempo~$\Cl{O}(kn^2)$. O Problema~\ref{DivConq:InternetTrouble} cabe perfeitamente no formato descrito por este problema e foi otimizado utilizando a técnica da divisão e conquista. Para provar que a otimização era possível, precisamos construir uma série de matrizes e provar que estas eram monótonas e que o problema original se reduzia a encontrar os mínimos destas matrizes.

Definimos a matriz de cortes ótimos~$P$ da recorrência~$E$. Para toda entrada~$\ell,j$ de~$E$ onde~$\ell > 1$ vale que~$P[\ell][j]$ é o menor valor em~$[j]$ que respeita~${ E[\ell][j] = A[1][P[\ell][j]] + A[P[\ell][j]][j] }$. É claro da definição de~$E$ que esta matriz existe. É fácil calcular, junto com~$E$, as entradas da matriz~$P$. Esta matriz representa as escolhas que devem ser feitas em cada busca de mínimo da definição~$E$ para encontrar os valores verdadeiros das entradas da matriz.

Se as linhas da matriz~$P$ forem todas monótonas, isto é, se vale~${ P[\ell][i] \leq P[\ell][i'] }$ sempre que~${ i,i' \in [n] }$ e~$i < i'$, é possível utilizar a divisão e conquista para resolver o problema. É fácil ver isso construindo matrizes~$B_\ell$ iguais às construídas na solução do Problema~\ref{DivConq:InternetTrouble} e verificando que~$P[\ell][i]$ é o índice de mínimo da linha~$i$ matriz~$B_\ell$.

Geralmente é uma boa prática, quando se está pensando em programação dinâmica, considerar a matriz~$P$ e pensar sobre suas propriedades. A observação de que as linhas desta matriz, quando monótonas, permitem a aplicação do método da divisão e conquista é uma boa maneira de perceber a pertinência desta otimização em problemas e configura uma habilidade especialmente útil em competições de programação.
